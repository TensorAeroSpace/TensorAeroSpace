# ğŸš€ TensorAeroSpace

<div align="center">

[![en](https://img.shields.io/badge/lang-en-red.svg)](./README.md)
[![ru](https://img.shields.io/badge/lang-ru-green.svg)](./README.ru-ru.md)
[![Documentation Status](https://readthedocs.org/projects/tensoraerospace/badge/?version=latest)](https://tensoraerospace.readthedocs.io/en/latest/?badge=latest)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![GitHub stars](https://img.shields.io/github/stars/tensoraerospace/tensoraerospace.svg)](https://github.com/tensoraerospace/tensoraerospace/stargazers)

![TensorAeroSpace Logo](./img/logo-no-background.png)

**Advanced Aerospace Control Systems & Reinforcement Learning Framework**

*A comprehensive Python library for aerospace simulation, control algorithms, and reinforcement learning implementations*

[ğŸ“– Documentation](https://tensoraerospace.readthedocs.io/) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ’¡ Examples](./example/) â€¢ [ğŸ¤ Contributing](CONTRIBUTING.md)

</div>

---

## ğŸŒŸ Overview

**TensorAeroSpace** is a cutting-edge Python framework that combines aerospace engineering with modern machine learning. It provides:

- ğŸ¯ **Control Systems**: Advanced control algorithms including PID, MPC, and modern RL approaches
- âœˆï¸ **Aerospace Models**: High-fidelity aircraft and spacecraft simulation models
- ğŸ® **OpenAI Gym Integration**: Ready-to-use environments for reinforcement learning
- ğŸ§  **RL Algorithms**: State-of-the-art reinforcement learning implementations
- ğŸ”§ **Extensible Architecture**: Easy to extend and customize for your specific needs

## ğŸš€ Quick Start

### ğŸ“¦ Installation

#### Using Poetry (Recommended)
```bash
git clone https://github.com/tensoraerospace/tensoraerospace.git
cd tensoraerospace
poetry install
```

#### Using pip
```bash
pip install tensoraerospace
```

#### ğŸ³ Docker
```bash
docker build -t tensoraerospace . --platform=linux/amd64
docker run -v $(pwd)/example:/app/example -p 8888:8888 -it tensoraerospace
```

### ğŸƒâ€â™‚ï¸ Quick Example

```python
import tensoraerospace as tas

# Create an F-16 environment
env = tas.envs.F16Env()

# Initialize a PPO agent
agent = tas.agent.PPO(env.observation_space, env.action_space)

# Train the agent
for episode in range(1000):
    obs = env.reset()
    done = False
    while not done:
        action = agent.act(obs)
        obs, reward, done, info = env.step(action)
```

## ğŸ¤– Supported Algorithms

| Algorithm | Type | HuggingFace Export | Status |
|-----------|------|:------------------:|:------:|
| **IHDP** | Incremental Heuristic Dynamic Programming | âŒ | âœ… |
| **DQN** | Deep Q-Learning | âŒ | âœ… |
| **SAC** | Soft Actor-Critic | âœ… | âœ… |
| **A3C** | Asynchronous Advantage Actor-Critic | âŒ | âœ… |
| **PPO** | Proximal Policy Optimization | âœ… | âœ… |
| **MPC** | Model Predictive Control | âœ… | âœ… |
| **A2C** | Advantage Actor-Critic | âœ… | âœ… |
| **A2C-NARX** | A2C with NARX Critic | âŒ | âœ… |
| **PID** | Proportional-Integral-Derivative | âœ… | âœ… |

## âœˆï¸ Aircraft & Spacecraft Models

<details>
<summary><b>ğŸ›©ï¸ Fixed-Wing Aircraft</b></summary>

- **General Dynamics F-16 Fighting Falcon** - High-fidelity fighter jet model
- **Boeing 747** - Commercial airliner dynamics
- **McDonnell Douglas F-4C Phantom II** - Military aircraft model
- **North American X-15** - Hypersonic research aircraft

</details>

<details>
<summary><b>ğŸš UAVs & Drones</b></summary>

- **LAPAN Surveillance Aircraft (LSU)-05** - Indonesian surveillance UAV
- **Ultrastick-25e** - RC aircraft model
- **Generic UAV State Space** - Configurable UAV dynamics

</details>

<details>
<summary><b>ğŸš€ Rockets & Satellites</b></summary>

- **ELV (Expendable Launch Vehicle)** - Launch vehicle dynamics
- **Generic Rocket Model** - Customizable rocket simulation
- **Geostationary Satellite** - Orbital mechanics simulation
- **Communication Satellite** - ComSat dynamics and control

</details>

## ğŸ® Simulation Environments

### ğŸ¯ Unity ML-Agents Integration

<div align="center">

![Unity Demo](./docs/example/env/img/img_demo_unity.gif)

</div>

TensorAeroSpace seamlessly integrates with Unity ML-Agents for immersive 3D simulations:

- ğŸ® **3D Visualization**: Real-time 3D aircraft simulation
- ğŸ”„ **Real-time Training**: Train agents in realistic environments
- ğŸ“Š **Rich Sensors**: Camera, LiDAR, and physics-based sensors
- ğŸŒ **Custom Environments**: Build your own aerospace scenarios

> ğŸ“ **Example Environment**: [UnityAirplaneEnvironment](https://github.com/TensorAeroSpace/UnityAirplaneEnvironment)

### ğŸ”§ MATLAB Simulink Support

![Simulink Model](docs/example/simulink/img/model.png)

- ğŸ“ **Model Import**: Convert Simulink models to Python
- âš¡ **High Performance**: Compiled C++ integration
- ğŸ”„ **Bidirectional**: MATLAB â†” Python workflow
- ğŸ“Š **Validation**: Cross-platform model validation

### ğŸ“Š State Space Matrices

Mathematical foundation for control system design:

- ğŸ§® **Linear Models**: State-space representation
- ğŸ›ï¸ **Control Design**: Modern control theory implementation
- ğŸ“ˆ **Analysis Tools**: Stability, controllability, observability
- ğŸ”„ **Linearization**: Nonlinear model linearization

## ğŸ“š Examples & Tutorials

Explore our comprehensive example collection in the [`./example`](./example/) directory:

| Category | Description | Notebooks |
|----------|-------------|-----------|
| ğŸš€ **Quick Start** | Basic usage and concepts | [`quickstart.ipynb`](./example/quickstart.ipynb) |
| ğŸ¤– **Reinforcement Learning** | RL algorithm implementations | [`reinforcement_learning/`](./example/reinforcement_learning/) |
| ğŸ›ï¸ **Control Systems** | PID, MPC controllers | [`pid_controllers/`](./example/pid_controllers/), [`mpc_controllers/`](./example/mpc_controllers/) |
| âœˆï¸ **Aircraft Models** | Environment examples | [`environments/`](./example/environments/) |
| ğŸ”§ **Optimization** | Hyperparameter tuning | [`optimization/`](./example/optimization/) |

## ğŸ› ï¸ Development & Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### ğŸ—ï¸ Development Setup

```bash
git clone https://github.com/tensoraerospace/tensoraerospace.git
cd tensoraerospace
poetry install --with dev
poetry run pytest  # Run tests
```

### ğŸ§ª Testing

```bash
# Run all tests
poetry run pytest

# Run specific test category
poetry run pytest tests/envs/
poetry run pytest tests/agents/
```

## ğŸ“– Documentation

- ğŸ“š **Full Documentation**: [tensoraerospace.readthedocs.io](https://tensoraerospace.readthedocs.io/)
- ğŸš€ **API Reference**: Detailed API documentation
- ğŸ“ **Tutorials**: Step-by-step guides
- ğŸ’¡ **Examples**: Practical use cases

## ğŸ¤ Community & Support

- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/tensoraerospace/tensoraerospace/discussions)
- ğŸ› **Issues**: [Bug Reports](https://github.com/tensoraerospace/tensoraerospace/issues)
- ğŸ“§ **Contact**: [Email Support](mailto:support@tensoraerospace.org)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI Gym team for the excellent RL framework
- Unity ML-Agents team for 3D simulation capabilities
- The aerospace engineering community for domain expertise
- All contributors who make this project possible

---

<div align="center">

**â­ Star us on GitHub if you find TensorAeroSpace useful! â­**

Made with â¤ï¸ by the TensorAeroSpace team

</div>
