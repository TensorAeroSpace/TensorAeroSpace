{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from tensoraerospace.envs.f16.linear_longitudial import LinearLongitudinalF16\n",
    "from tensoraerospace.utils import generate_time_period, convert_tp_to_sec_tp\n",
    "from tensoraerospace.signals.standart import unit_step, sinusoid\n",
    "from tensoraerospace.benchmark.function import overshoot, settling_time, static_error\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация списка для хранения исторических данных\n",
    "hist = []\n",
    "dt = 0.01  # Интервал дискретизации времени\n",
    "\n",
    "# Генерация временного периода с заданным интервалом дискретизации\n",
    "tp = generate_time_period(tn=5, dt=dt) \n",
    "\n",
    "# Конвертация временного периода в секунды\n",
    "tps = convert_tp_to_sec_tp(tp, dt=dt)\n",
    "\n",
    "# Вычисление общего количества временных шагов\n",
    "number_time_steps = len(tp) \n",
    "\n",
    "# Создание заданного сигнала с использованием единичного шага\n",
    "# reference_signals = np.reshape(unit_step(degree=0, tp=tp, time_step=20, output_rad=True), [1, -1])\n",
    "reference_signals = np.reshape(np.deg2rad(sinusoid(amplitude=0.01, tp=tp, frequency=5)), [1, -1])\n",
    "\n",
    "# Создание среды симуляции, задание временных шагов, начального состояния, заданного сигнала и отслеживаемых состояний\n",
    "env = gym.make('LinearLongitudinalF16-v0',\n",
    "               number_time_steps=number_time_steps, \n",
    "               initial_state=[[0],[0],[0],[0]],\n",
    "               reference_signal=reference_signals,\n",
    "               tracking_states=[\"alpha\"])\n",
    "\n",
    "# Сброс среды к начальному состоянию\n",
    "state, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(tps, sinusoid(amplitude=0.01, tp=tp, frequency=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensoraerospace.agent.mpc.nn import MPCAgent, Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "seed = 7777777\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "def example_cost_function(state, action):\n",
    "    theta = state[0, 0].item()\n",
    "    theta_dot = state[0, 1].item()\n",
    "    return (theta ** 2 + 0.1 * theta_dot ** 2 + 0.001 * (action ** 2))\n",
    "\n",
    "# Assuming `model`, `env`, and other necessary variables are defined elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(next_state, action, reference_signals, step):\n",
    "    # Коэффициенты веса для ошибки состояния и управляющего действия\n",
    "    Q = 10.0  # Вес ошибки состояния\n",
    "    R = 0.01  # Вес управляющего действия\n",
    "    \n",
    "    # Извлечение текущих значений угла атаки и угловой скорости\n",
    "    alpha, omega = next_state[0].detach().numpy()\n",
    "    \n",
    "    # Получение желаемого значения угла атаки на текущем шаге\n",
    "    alpha_ref = reference_signals[0][step]\n",
    "    # Расчет ошибки состояния (разница между текущим и желаемым углом атаки)\n",
    "    state_error = abs(alpha - alpha_ref)\n",
    "    \n",
    "    # Расчет стоимости на основе ошибки состояния и управляющего действия\n",
    "    cost = Q * (state_error**2) \n",
    "    return cost\n",
    "\n",
    "agent = MPCAgent(gamma=0.99, action_dim=1, observation_dim=2, model=model, cost_function=cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, next_states = agent.collect_data(env, num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train_model(states, actions, next_states, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, next_states = agent.collect_data(env, num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test_network(states, actions, next_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout, horizon = 50,10\n",
    "for episode in range(1):\n",
    "    state, info = env.reset()\n",
    "    state = state.reshape([1, -1])[0]\n",
    "    episode_reward = 0\n",
    "    for step in tqdm(range(number_time_steps-2)):\n",
    "        action = agent.choose_action_ref(state, rollout, horizon, reference_signals, step)\n",
    "        state, reward, terminated, truncated, info= env.step(action)\n",
    "        state = state.reshape([1, -1])[0]\n",
    "        done = terminated or truncated\n",
    "        episode_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    print('rollout: %d, horizon: %d, episode: %d, reward: %d' % (rollout, horizon, episode, episode_reward))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.model.plot_control('ele', tps, to_deg=True, figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.model.plot_transient_process('alpha', tps, reference_signals[0], to_deg=True, figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
