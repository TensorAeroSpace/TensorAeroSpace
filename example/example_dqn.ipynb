{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример работы алгоритма dqn и unity среды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем dqn агента и модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WZWDSMmKtfq4"
   },
   "outputs": [],
   "source": [
    "from tensorairspace.agent.dqn.model import Model, PERAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем unity среду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorairspace.envs.unity_env import get_plane_env, unity_discrete_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная ячейка создаёт агента и запускает взаимодействие с unity средой.\n",
    "\n",
    "После запуска взаимодействия со средой необходимо запустить сцену со средой в Unity editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQXQrCT7uEz-",
    "outputId": "183d23cd-b440-4c45-cd23-2dfb8f1e376e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[WARNING] uint8_visual was set to true, but visual observations are not in use. This setting will not have any effect.\n",
      "[WARNING] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.\n",
      "After Training: -500 out of 200\n"
     ]
    }
   ],
   "source": [
    "env = unity_discrete_env()\n",
    "num_actions = env.action_space.n\n",
    "model = Model(num_actions)\n",
    "target_model = Model(num_actions)\n",
    "agent = PERAgent(model, target_model, env, train_nums=100)\n",
    "agent.train()\n",
    "# test after\n",
    "# env = gym.wrappers.Monitor(env, './recording', force=True)\n",
    "rewards_sum = agent.evaluation(env)\n",
    "print(\"After Training: %d out of 200\" % rewards_sum)  # 200 out of 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная ячейка показывает взаимодействие с unity средой случайного агента.\n",
    "\n",
    "После запуска взаимодействия со средой необходимо запустить сцену со средой в Unity editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: My Behavior?team=0\n",
      "[WARNING] uint8_visual was set to true, but visual observations are not in use. This setting will not have any effect.\n",
      "[WARNING] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.\n",
      "Discrete(2187)\n",
      "1874\n",
      "342\n",
      "719\n",
      "1\n",
      "582\n",
      "2177\n",
      "70\n",
      "599\n",
      "12\n",
      "2056\n",
      "21\n",
      "90\n",
      "1938\n",
      "1879\n",
      "1572\n",
      "1268\n",
      "593\n",
      "670\n",
      "2165\n",
      "1888\n",
      "1583\n",
      "455\n",
      "222\n",
      "1006\n",
      "1176\n",
      "1553\n",
      "884\n",
      "2121\n",
      "1643\n",
      "1124\n",
      "1743\n",
      "275\n",
      "449\n",
      "643\n",
      "968\n",
      "1412\n",
      "1597\n",
      "759\n",
      "1835\n",
      "1861\n",
      "517\n",
      "652\n",
      "929\n",
      "1151\n",
      "1991\n",
      "1860\n",
      "1656\n",
      "1512\n",
      "712\n",
      "374\n",
      "715\n",
      "1736\n",
      "566\n",
      "1583\n",
      "128\n",
      "1530\n",
      "367\n",
      "988\n",
      "2177\n",
      "1221\n",
      "2040\n",
      "49\n",
      "1255\n",
      "1659\n",
      "1001\n",
      "397\n",
      "1638\n",
      "1426\n",
      "944\n",
      "1291\n",
      "963\n",
      "269\n",
      "1225\n",
      "1802\n",
      "1655\n",
      "733\n",
      "401\n",
      "1941\n",
      "1655\n",
      "1517\n",
      "215\n",
      "1340\n",
      "1496\n",
      "2116\n",
      "1090\n",
      "941\n",
      "1033\n",
      "200\n",
      "729\n",
      "666\n",
      "1377\n",
      "1817\n",
      "2068\n",
      "296\n",
      "235\n",
      "1736\n",
      "542\n",
      "1961\n",
      "1075\n",
      "1110\n"
     ]
    }
   ],
   "source": [
    "env = unity_discrete_env()\n",
    "\n",
    "env.reset()\n",
    "\n",
    "print(env.action_space)\n",
    "\n",
    "for i in range(100):\n",
    "    random_action = env.action_space.sample()\n",
    "    print(random_action)\n",
    "    new_obs, reward, done, info = env.step(random_action)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "example_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
